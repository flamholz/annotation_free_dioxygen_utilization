'''Tests for the training and validation datasets generated by the build_datasets.py script.'''
import pandas as pd
import unittest
from aerobot.io import DATA_PATH, FEATURE_TYPES
from aerobot.dataset import dataset_load_training_testing_validation
from parameterized import parameterized
import numpy as np
import math

# TODO: Add "sanity check" test cases for organisms which we KNOW should be facultative, aerobe, etc.


class DatasetTests(unittest.TestCase):
    '''Unit tests for the training and validation data representations.'''

    def _test_more_labels_than_features(self, features:pd.DataFrame=None, labels:pd.DataFrame=None):
        # There should always be more labels (or equal to) than features.
        self.assertGreaterEqual(len(labels), len(features))

    def _test_label_and_feature_indices_match(self, features:pd.DataFrame=None, labels:pd.DataFrame=None):
        # Merge the labels and features on the index.
        merged_features = features.merge(labels, left_index=True, right_index=True, how='left')
        self.assertTrue(len(merged_features) == len(features)) # Make sure there is one label for every feature.

    def _test_no_duplicate_entries(self, features:pd.DataFrame=None, labels:pd.DataFrame=None):
        self.assertTrue(features.index.is_unique)
        self.assertTrue(labels.index.is_unique)
    
    def _test_no_nan_entries(self, features:pd.DataFrame=None, labels:pd.DataFrame=None):
        '''Test to make sure none of the datasets contain NaNs. All should have been filled in with zeros.'''
        self.assertTrue(np.all(~features.isnull().values.ravel()))

    @parameterized.expand(FEATURE_TYPES)
    def test_correct_type_in_numpy_arrays(self, feature_type:str):
        # Making sure that the index or column values don't end up in the data used to train models. 
        # I doubt this is happening, but just want to confirm. 
  
        # Load in the training and testing datasets as numpy arrays.
        datasets = dataset_load_training_testing_validation(feature_type, to_numpy=True)
        # Make sure everything is actually a numpy array of floats (or strings, in the case of labels).
        for dataset in datasets.values():
            features_dtype = dataset['features'].dtype
            labels_dtype = dataset['labels'].dtype
            self.assertTrue(features_dtype == np.float32, msg=f'Observed feature data type is {features_dtype}, expected np.float32.')
            self.assertTrue(labels_dtype == np.object_, msg=f'Observed labels data type is {labels_dtype}, expected {np.object_}.')

    @parameterized.expand(FEATURE_TYPES)
    def test_feature_type_datasets(self, feature_type:str):
        # Load in the training and validation sets as pandas DataFrames.
        datasets = dataset_load_training_testing_validation(feature_type, to_numpy=False)
        for dataset in datasets.values(): # Run a series of tests checking for consistency within each dataset.
            self._test_more_labels_than_features(**dataset)
            self._test_label_and_feature_indices_match(**dataset)
            self._test_no_duplicate_entries(**dataset)
            self._test_no_nan_entries(**dataset)

    @parameterized.expand(FEATURE_TYPES)
    def test_datasets_are_disjoint(self, feature_type:str):
        # Load in the training and validation sets as pandas DataFrames
        datasets = dataset_load_training_testing_validation(feature_type, to_numpy=False)
        train_ids, val_ids, test_ids = datasets['training']['features'].index, datasets['validation']['features'].index, datasets['testing']['features'].index
        # Already testing for no duplicate entries, so assume elements in training_ids and validation_ids are already unique.
        all_ids = np.concatenate([train_ids, val_ids, test_ids]).ravel()
        # Make sure there are no IDs in the training and validation datasets.
        self.assertTrue(len(all_ids) == len(np.unique(all_ids)))

    @parameterized.expand(FEATURE_TYPES)
    def test_datasets_are_the_correct_size(self, feature_type:str):
        datasets = dataset_load_training_testing_validation(feature_type, to_numpy=False)
        train_size, val_size, test_size = len(datasets['training']['features']), len(datasets['validation']['features']), len(datasets['testing']['features'])
        N = train_size + val_size + test_size 

        self.assertTrue(math.isclose(test_size/N, 0.2, abs_tol=0.1), msg=f'Testing data is {np.round(test_size/N, 2)} of total data.')
        self.assertTrue(math.isclose(train_size/N, 0.8 * 0.8, abs_tol=0.1), msg=f'Training data is {np.round(train_size/N, 2)} of total data.')
        self.assertTrue(math.isclose(val_size/N, 0.16, abs_tol=0.1), msg=f'Validation data is {np.round(val_size/N, 2)} of total data.')

if __name__ == '__main__':
    unittest.main()