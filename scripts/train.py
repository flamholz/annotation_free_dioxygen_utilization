from aerobot.models import LinearClassifier, NonlinearClassifier, LogisticClassifier
import argparse
from aerobot.utils import FEATURE_TYPES, save_results_dict
import time
from aerobot.dataset import FeatureDataset, FEATURE_TYPES
import os
import numpy as np
import json 
from typing import Dict
import torch

def load_datasets(feature_type:str, data_path:str=None):
    '''Load the training, testing, and validation datasets generated by the build.py (or build-rna16s.py) script.'''
    datasets = dict()
    for dataset_type in ['training', 'testing', 'validation']:
        datasets[dataset_type] = FeatureDataset(os.path.join(data_path, f'{dataset_type}_dataset.h5'), feature_type=feature_type)
    return datasets


torch.manual_seed(42) # Seed the RNG for reproducibility.
np.random.seed(42)

if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument('model-class', choices=['nonlinear', 'linear', 'logistic'])
    parser.add_argument('feature-type', type=str, default=None, choices=FEATURE_TYPES + ['embedding_rna16s'])
    parser.add_argument('--n-classes', default=3, type=int)
    parser.add_argument('--model-path', default='../models/')
    parser.add_argument('--data-path', default='../data/')
    parser.add_argument('--output_path', default='.')

    t1 = time.perf_counter()
    args = parser.parse_args()

    feature_type = getattr(args, 'feature-type')
    model_class = getattr(args, 'model-class')

    datasets = load_datasets(feature_type, data_path=args.data_path) 

    if model_class == 'nonlinear':
        model = NonlinearClassifier(output_dim=args.n_classes, input_dim=datasets['training'].shape[-1])
        model.fit(datasets['training'], datasets['validation'])
    elif model_class == 'linear':
        model = LinearClassifier(output_dim=args.n_classes, input_dim=datasets['training'].shape[-1])
        model.fit(datasets['training'], datasets['validation'])
    elif model_class == 'logistic':
        model = LogisticClassifier(n_classes=args.n_classes)
        model.fit(datasets['training'])

    results = dict()
    results['n_classes'] = args.n_classes
    results['train_acc'] = model.accuracy(datasets['training'])
    results['test_acc'] = model.accuracy(datasets['testing'])
    results['val_acc'] = model.accuracy(datasets['validation'])
    results['confusion_matrix'] = model.confusion_matrix(datasets['testing']).ravel()
    results['val_accs'] = None if not hasattr(model, 'val_accs') else model.val_accs
    results['train_accs'] = None if not hasattr(model, 'train_accs') else model.train_accs
    results['val_losses'] = None if not hasattr(model, 'val_losses') else model.val_losses
    results['train_losses'] = None if not hasattr(model, 'train_losses') else model.val_accs
   
    print('Balanced accuracy on training dataset:', results['train_acc'])
    print('Balanced accuracy on testing dataset:', results['test_acc'])
    print('Balanced accuracy on validation dataset:', results['val_acc'])
    
    task = 'binary' if args.n_classes == 2 else 'ternary'
    output_path = os.path.join(args.output_path, f'train_{model_class}_{feature_type}_{task}.json')
    print(f'\nWriting results to {output_path}.')
    save_results_dict(results, output_path)

    model_path = os.path.join(args.model_path, f'{model_class}_{feature_type}_{task}.joblib')
    print(f'Saving trained model to {model_path}.')
    model.save(model_path)

    t2 = time.perf_counter()
    print(f'\nModel training complete in {np.round(t2 - t1, 2)} seconds.')

